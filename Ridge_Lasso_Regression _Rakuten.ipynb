{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Numerical libraries\n",
    "import numpy as np   \n",
    "\n",
    "# Import Linear Regression machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# to handle data in form of rows and columns \n",
    "import pandas as pd    \n",
    "\n",
    "# importing ploting libraries\n",
    "import matplotlib.pyplot as plt   \n",
    "\n",
    "#importing seaborn for statistical plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df = pd.read_csv(\"car-mpg.csv\")  \n",
    "mpg_df = mpg_df.drop('car_name', axis=1)\n",
    "mpg_df['origin'] = mpg_df['origin'].replace({1: 'america', 2: 'europe', 3: 'asia'})\n",
    "mpg_df = pd.get_dummies(mpg_df, columns=['origin'])\n",
    "mpg_df = mpg_df.replace('?', np.nan)\n",
    "mpg_df = mpg_df.apply(lambda x: x.fillna(x.median()),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separate independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all the predictor variables into X dataframe. Since 'mpg' is dependent variable drop it\n",
    "X = mpg_df.drop('mpg', axis=1)\n",
    "\n",
    "# Copy the 'mpg' column alone into the y dataframe. This is the dependent variable\n",
    "y = mpg_df[['mpg']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# scale all the columns of the mpg_df. This will produce a numpy array\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)  # ideally the training and test should be \n",
    "\n",
    "y_scaled = preprocessing.scale(y)\n",
    "y_scaled = pd.DataFrame(y_scaled, columns=y.columns)  # ideally the training and test should be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit a simple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for cyl is 0.3210223856916117\n",
      "The coefficient for disp is 0.3248343091848392\n",
      "The coefficient for hp is -0.2291695005943764\n",
      "The coefficient for wt is -0.7112101905072299\n",
      "The coefficient for acc is 0.014713682764191103\n",
      "The coefficient for yr is 0.3755811949510745\n",
      "The coefficient for car_type is 0.3814769484233109\n",
      "The coefficient for origin_america is -0.07472247547584175\n",
      "The coefficient for origin_asia is 0.04451525203567832\n",
      "The coefficient for origin_europe is 0.04834854953945405\n"
     ]
    }
   ],
   "source": [
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)\n",
    "\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, regression_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept for our model is 0.019284116103639757\n"
     ]
    }
   ],
   "source": [
    "intercept = regression_model.intercept_[0]\n",
    "\n",
    "print(\"The intercept for our model is {}\".format(intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a regularized RIDGE model and note the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model: [[ 0.31649043  0.31320707 -0.22876025 -0.70109447  0.01295851  0.37447352\n",
      "   0.37725608 -0.07423624  0.04441039  0.04784031]]\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=.3)\n",
    "ridge.fit(X_train,y_train)\n",
    "print (\"Ridge model:\", (ridge.coef_))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a regularized LASSO model and note the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model: [-0.         -0.         -0.01690287 -0.51890013  0.          0.28138241\n",
      "  0.1278489  -0.01642647  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train,y_train)\n",
    "print (\"Lasso model:\", (lasso.coef_))\n",
    "\n",
    "# Observe, many of the coefficients have become 0 indicating drop of those dimensions from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us compare their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8343770256960538\n",
      "0.8513421387780066\n"
     ]
    }
   ],
   "source": [
    "print(regression_model.score(X_train, y_train))\n",
    "print(regression_model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8343617931312616\n",
      "0.8518882171608507\n"
     ]
    }
   ],
   "source": [
    "print(ridge.score(X_train, y_train))\n",
    "print(ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7938010766228453\n",
      "0.8375229615977083\n"
     ]
    }
   ],
   "source": [
    "print(lasso.score(X_train, y_train))\n",
    "print(lasso.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More or less similar results but with less complex models.  Complexity is a function of variables and coefficients\n",
    "## Note - with Lasso, we get equally good result in test though not so in training.  Further, the number of dimensions is much less\n",
    "# in LASSO model than ridge or un-regularized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us generate polynomial models reflecting the non-linear interaction between some dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2, interaction_only=True)\n",
    "\n",
    "#poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 56)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly = poly.fit_transform(X_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.30, random_state=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a simple non regularized linear model on poly features-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.24082770e-13 -1.14204220e+12 -4.43738735e+00 -2.24947964e+00\n",
      " -2.98166341e+00 -1.56730367e+00  3.00442772e+00 -1.52060575e+12\n",
      " -7.80788356e+11  3.71375223e+12 -3.23609457e+12 -1.15918732e+00\n",
      " -1.43925476e+00 -3.57818604e-03  2.58444214e+00 -1.91918182e+00\n",
      " -3.65891647e+12 -6.45319147e+12 -2.39436996e+12 -2.28543203e+12\n",
      "  3.90441895e-01  2.09503174e-01 -4.23446655e-01  3.58471680e+00\n",
      " -2.02703094e+00 -9.03672940e+11 -7.44778888e+11 -7.10893285e+11\n",
      "  2.47772217e-01 -6.70440674e-01 -1.92620850e+00 -7.47558594e-01\n",
      " -2.15947171e+11 -1.77976884e+11 -1.69879374e+11 -1.72500610e-01\n",
      "  5.30212402e-01 -3.32050323e+00  1.69388998e+12  1.39605098e+12\n",
      "  1.33253411e+12  5.85876465e-01  1.53894043e+00  4.76389633e+11\n",
      "  3.92625390e+11  3.74761903e+11  4.00207520e-01 -1.27131857e+10\n",
      " -1.04778089e+10 -1.00010944e+10 -1.09798815e+12  8.13175594e+11\n",
      "  7.76178109e+11  2.20248210e+11 -5.15971535e+12  2.83957085e+12]\n"
     ]
    }
   ],
   "source": [
    "regression_model.fit(X_train, y_train)\n",
    "print(regression_model.coef_[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model: [[ 0.          3.73512981 -2.93500874 -2.13974194 -3.56547812 -1.28898893\n",
      "   3.01290805  2.04739082  0.0786974   0.21972225 -0.3302341  -1.46231096\n",
      "  -1.17221896  0.00856067  2.48054694 -1.67596093  0.99537516 -2.29024279\n",
      "   4.7699338  -2.08598898  0.34009408  0.35024058 -0.41761834  3.06970569\n",
      "  -2.21649433  1.86339518 -2.62934278  0.38596397  0.12088534 -0.53440382\n",
      "  -1.88265835 -0.7675926  -0.90146842  0.52416091  0.59678246 -0.26349448\n",
      "   0.5827378  -3.02842915 -0.36548074  0.5956112  -0.15941014  0.49168856\n",
      "   1.45652375 -0.43819158 -0.20964198  0.77665496  0.36489921 -0.4750838\n",
      "   0.3551047   0.23188557 -1.42941282  2.06831543 -0.34986402 -0.32320394\n",
      "   0.39054656  0.06283411]]\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=.3)\n",
    "ridge.fit(X_train,y_train)\n",
    "print (\"Ridge model:\", (ridge.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9143225702003365\n",
      "0.861339805369854\n"
     ]
    }
   ],
   "source": [
    "print(ridge.score(X_train, y_train))\n",
    "print(ridge.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso model: [ 0.          0.52263805 -0.5402102  -1.99423315 -4.55360385 -0.85285179\n",
      "  2.99044036  0.00711821 -0.          0.76073274 -0.         -0.\n",
      " -0.19736449  0.          2.04221833 -1.00014513  0.         -0.\n",
      "  4.28412669 -0.          0.          0.31442062 -0.          2.13894094\n",
      " -1.06760107  0.         -0.          0.          0.         -0.44991392\n",
      " -1.55885506 -0.         -0.68837902  0.          0.17455864 -0.34653644\n",
      "  0.3313704  -2.84931966  0.         -0.34340563  0.00815105  0.47019445\n",
      "  1.25759712 -0.69634581  0.          0.55528147  0.2948979  -0.67289549\n",
      "  0.06490671  0.         -1.19639935  1.06711702  0.         -0.88034391\n",
      "  0.         -0.        ]\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X_train,y_train)\n",
    "print (\"Lasso model:\", (lasso.coef_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9098286193898272\n",
      "0.8695296858772456\n"
     ]
    }
   ],
   "source": [
    "print(lasso.score(X_train, y_train))\n",
    "print(lasso.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
